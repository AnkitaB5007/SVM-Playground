{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d4ef62",
   "metadata": {},
   "source": [
    "# SVM Classification Experiments on Breast Cancer Dataset\n",
    "\n",
    "This notebook explores Support Vector Machine (SVM) classification using the breast cancer dataset from scikit-learn. Experiments with different kernels, hyperparameters, and analysis of results will follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a67a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fb17f",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "Load the breast cancer dataset and explor its structure, features, and target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc26453-cb19-428a-aecf-1f377f937535",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ebcdb-22ab-49de-a031-5b3e713edfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples vs num of features: {X.shape}\")\n",
    "print(f\"Feature names: {data.feature_names[:5]}...\")\n",
    "print(f\"Target names: {data.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f831d-a2ab-4fab-9797-ef1ba2e95325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is the data balanced? : {np.bincount(y)}\") # 212 malignant cases and 357 benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c001-342e-43dd-91a9-07df15d4badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X, columns= data.feature_names)\n",
    "# df['target'] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "df['target_name'] = df['target'].map({0: 'malignant', 1: 'benign'})\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963a339-6755-4b88-9256-284edb296f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Count plot\n",
    "target_counts = df['target_name'].value_counts()\n",
    "print(\"Target counts\", target_counts)\n",
    "ax1.bar(target_counts.index, target_counts.values)\n",
    "\n",
    "ax1.set_title('Target Distribution')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%')\n",
    "ax2.set_title('Target Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc35b28",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Scaling\n",
    "\n",
    "Now we'll split the data into training and testing sets and apply feature scaling, which is crucial for SVM performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9437ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Training target distribution M vs B:\", np.bincount(y_train))\n",
    "print(\"Testing target distribution M vs B:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c3885-ef7e-414d-b65a-71563c9b2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature distributions before and after scaling\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Before scaling\n",
    "ax1.boxplot(X_train[:, :5]) # For demo, uswing 5features\n",
    "ax1.set_title('Feature Distribution Before Scaling')\n",
    "ax1.set_xlabel('Feature Index')\n",
    "ax1.set_ylabel('Value')\n",
    "\n",
    "# After scaling\n",
    "ax2.boxplot(X_train_scaled[:, :5])\n",
    "ax2.set_title('After Scaling')\n",
    "ax2.set_xlabel('Feature Index')\n",
    "ax2.set_ylabel('Scaled Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4d781",
   "metadata": {},
   "source": [
    "## 3. Train SVM Model with Linear Kernel\n",
    "\n",
    "Let's start with a basic SVM model using a linear kernel, similar to your original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM model with linear kernel\n",
    "svm_linear = SVC(kernel='linear', random_state=42)\n",
    "# Train\n",
    "svm_linear.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9d8a1-8eb5-4867-bc26-6872d8df7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_linear = svm_linear.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4083099-087c-4568-a199-55ee8fb40d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "print(f\"Linear SVM Accuracy: {accuracy_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e69931-0d1a-4846-bd6e-eeed881023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get support vectors information\n",
    "# This means:15 training samples from the \"Malignant\" class are support vectors. 17 training samples from the \"Benign\" class are support vectors.\n",
    "print(f\"Number of support vectors: {svm_linear.n_support_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfb015",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Performance Metrics\n",
    "\n",
    "Evaluatiom the linear SVM model using various performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_lin = confusion_matrix(y_test, y_pred_linear)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a2efa-7ac3-4e4d-85d4-382b61ba2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lin, annot=True, fmt='d', cmap='Purples', \n",
    "            xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "\n",
    "plt.title('Confusion Matrix - Linear SVM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b98052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Report\n",
    "print(classification_report(y_test, y_pred_linear, target_names=data.target_names))\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(svm_linear, X_train_scaled, y_train, cv=5)\n",
    "print(f\"\\nCross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc470c",
   "metadata": {},
   "source": [
    "## 5.Different SVM Kernels\n",
    "\n",
    "different SVM kernels: linear, RBF, and polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1db22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different kernels to test\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "svm_models = {}\n",
    "predictions = {}\n",
    "accuracies = {}\n",
    "\n",
    "# Train and evaluate each kernel\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTraining SVM with {kernel} kernel...\")\n",
    "    \n",
    "    # train model\n",
    "    model = SVC(kernel=kernel, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # results\n",
    "    svm_models[kernel] = model\n",
    "    predictions[kernel] = y_pred\n",
    "    accuracies[kernel] = accuracy\n",
    "    \n",
    "    print(f\"{kernel.upper()} SVM Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Number of support vectors: {model.n_support_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd4c44",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning with Grid Search\n",
    "\n",
    "Let's use GridSearchCV to find the optimal hyperparameters for our SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids for different kernels\n",
    "param_grids = {\n",
    "    'linear': {\n",
    "        'kernel': ['linear'],\n",
    "        'C': [0.1, 1, 10, 100]\n",
    "    },\n",
    "    'rbf': {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    'poly': {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'degree': [2, 3, 4],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff52b4c-a0d7-4463-827e-8b82262ae55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "# Perform grid search for each kernel\n",
    "for kernel_name, param_grid in param_grids.items():\n",
    "    print(f\"\\nPerforming Grid Search for {kernel_name} kernel.\")\n",
    "    \n",
    "    # Create SVM model\n",
    "    svm = SVC(random_state=42)\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Store best model and score\n",
    "    best_models[kernel_name] = grid_search.best_estimator_\n",
    "    best_scores[kernel_name] = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4122c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best models on test set\n",
    "print(\"Best Model Performance on Test Set:\")\n",
    "\n",
    "test_scores = {}\n",
    "for kernel_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_scores[kernel_name] = test_accuracy\n",
    "    \n",
    "    print(f\"\\n{kernel_name.upper()} SVM:\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Parameters: {model.get_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f40fc",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "\n",
    "Finally, analyze feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for kernel_name, model in best_models.items():\n",
    "    # Get prediction probabilities\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        y_scores = model.decision_function(X_test_scaled)\n",
    "    else:\n",
    "        y_scores = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, linewidth=2, \n",
    "             label=f'{kernel_name.upper()} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = best_models['linear']\n",
    "feature_importance = np.abs(linear_model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e9f69-be17-4cc9-9ddd-5730a674437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame({\n",
    "    'feature': data.feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f7544-6738-4e6c-9733-7402bded1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e034d-188b-468f-bfab-6cf857f7b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 most important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_feats = feature_df.head(15)\n",
    "plt.barh(range(len(top_feats)), top_feats['importance'])\n",
    "plt.yticks(range(len(top_feats)), top_feats['feature'])\n",
    "plt.xlabel('Feature Importance (Absolute Coefficient)')\n",
    "plt.title('Top 15 Most Important Features (Linear SVM)')\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b600f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisatin using PCA\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b468e-3d0e-427c-9dd5-64e7226cfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50d73f-7855-44f2-b453-369b0968316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple SVM on PCA-reduced data for visualization\n",
    "svm_viz = SVC(kernel='rbf', random_state=42)\n",
    "svm_viz.fit(X_train_pca, y_train)\n",
    "\n",
    "# Create a mesh for decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(12, 8))\n",
    "Z = svm_viz.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "# Plot data points\n",
    "scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap=plt.cm.RdYlBu)\n",
    "plt.xlabel(f'First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]:.2f})')\n",
    "plt.ylabel(f'Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]:.2f})')\n",
    "plt.title('SVM Decision Boundary (2D PCA Projection)')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained by first 2 components: {pca.explained_variance_ratio_.sum():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
